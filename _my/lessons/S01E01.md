![](https://cloud.overment.com/S01E01-1730570331.png)
## Interakcja z dużym modelem językowym

Zdolność dużych modeli językowych do generowania ustrukturyzowanych treści umożliwia ich integrację z logiką aplikacji, co pozwala programistycznie sterować ich zachowaniem. Na obecnym etapie rozwoju pełnią rolę narzędzia, które umożliwia przetwarzanie i generowanie danych w sposób dotąd niemożliwy do osiągnięcia programistycznie (np. z pomocą wyrażeń regularnych).

W AI_devs 3 skupimy się na programistycznej interakcji z dużymi modelami językowymi poprzez API, budując częściowo-autonomiczne narzędzia zwane "Agentami AI". To złożone rozwiązania wymagające praktycznego doświadczenia w programowaniu i dobrego zrozumienia natury dużych modeli językowych.

Narzędzia te mogą realizować najróżniejsze zadania i procesy, ale nie są uniwersalne. Dlatego **skupimy się na tworzeniu ich indywidualnych komponentów oraz modułów.** W ten sposób możliwe będzie ich połączenie w różnych konfiguracjach i dopasowanie do naszych potrzeb. 

Jeszcze kilkanaście miesięcy temu wybór modelu ogólnego zastosowania praktycznie zaczynał się i kończył na OpenAI. Natomiast dziś pod uwagę możemy brać: 

- OpenAI: Modele z rodziny o1, GPT, w tym także TTS, Whisper i Embedding
- Anthropic: Modele z rodziny Claude (tylko tekst + obraz)
- Vertex AI (Google): Modele Gemini oraz wybranych dostawców (np. Anthropic) i inne
- [xAI](https://accounts.x.ai): Modele Grok, które dość szybko przebiły się na szczyty rankingów (top10). 
- Amazon Bedrock (Amazon): Modele Anthropic, Mistral czy Meta i inne
- Azure (Microsoft): Modele OpenAI, Meta i inne
- Groq: Modele Open Source, np. Llama
- a także kilka innych, np.: OpenRouter, Perplexity, Cerebras, Databricks, Mistral AI czy Together AI

Możemy zatem wybierać między różnymi ofertami cenowymi, limitami dostępu do API, polityką prywatności i przetwarzania danych, a także samymi modelami. Jest to istotne, ponieważ agenci AI będą autonomicznie korzystać z naszych baz wiedzy lub uzyskają dostęp do narzędzi. Przełoży się to na działanie na dość dużej skali, uwzględniającej przetwarzanie nawet dziesiątek milionów tokenów, co generuje zauważalne koszty. Obrazuje to poniższy przykład zapytania z prośbą do Agenta AI o zapisanie zadań w [Linear](https://linear.app/), co przełożyło się na 17,400 tokenów zapytania (input) i 461 tokenów odpowiedzi (output). Warto też zwrócić uwagę na czas wykonania zapytania, czyli "aż" 24 sekundy. 

![Przykład zapytania do Agenta AI z prośbą o zarządzanie zadaniami obrazuje skalę przetwarzanych tokenów oraz czasu reakcji](https://cloud.overment.com/2024-09-02/aidevs3_usage-c1dee228-3.png)

**Jedna wiadomość, kilka podjętych działań, niemal 18 tysięcy tokenów i pół minuty na reakcję** — z boku brzmi to, jak rozwiązanie, które nie ma sensu. Spójrzmy jednak na nie z nieco innej perspektywy.

Zarządzanie zadaniami **wymaga aktywnego działania ze strony osoby** obsługującej urządzenie z aplikacją taką jak Linear, Todoist czy ClickUp. Zadanie musi zostać nazwane, opisane, przypisane do kategorii, daty, priorytetu czy projektu **— w ten sposób pracuje większość z nas.**

![Obsługa aplikacji niemal zawsze wymaga bezpośredniego zaangażowania człowieka, który kontroluje cały proces](https://cloud.overment.com/2024-09-02/aidevs3_human-1e0045b9-1.png)

Proces ten można częściowo zautomatyzować. Przykładowo, możemy za pomocą API monitorować skrzynkę e-mail oraz pojawiające się słowa kluczowe. Na ich podstawie możliwe jest ustawienie reguł przekierowujących wiadomość do wskazanej osoby lub nawet utworzenie nowego wpisu w aplikacji do zadań. **Tutaj zaangażowanie człowieka nie jest wymagane, lecz potrzebny jest zestaw programistycznie zdefiniowanych zasad (co nie zawsze jest możliwe)** — mówimy więc tutaj o automatyzacji procesu według ściśle określonych reguł.

![Procesy prywatne i biznesowe mogą być automatyzowane według sztywnych reguł, np. dopasowania słów kluczowych](https://cloud.overment.com/2024-09-02/aidevs3_email-641f6178-2.png)

Teraz do budowy takiego systemu możemy wykorzystać duże modele językowe. Dzięki nim możemy przyjmować różne formy treści pochodzące z różnych źródeł, ponieważ za ich interpretację oraz podejmowane działania odpowiada model połączony z logiką aplikacji. 

Taki system może otrzymywać dane w formie zwykłych wiadomości pochodzących od innej osoby, a także poprzez zdjęcia z telefonu, nagrania głosowe z zegarka czy wiadomości przesłane na laptopie lub z zewnętrznego API. Co więcej, źródłem danych może być nawet **inny agent AI!**

W poniższym schemacie widzimy, że wszystkie źródła danych generują **zapytanie**, które jest interpretowane przez duży model językowy, na podstawie którego generowany jest plan działań i podejmowane są akcje.

![Automatyzacja w połączeniu z dużym modelem językowym pozwala na dość swobodne transformowanie różnych formatów treści, a także dynamiczne dostosowanie się do sytuacji](https://cloud.overment.com/2024-09-02/aidevs_agent-e32d845c-6.png)

Szczególnie interesujący jest tutaj fakt, że podczas realizowania powyższej logiki, możliwe jest dynamiczne uzyskiwanie dostępu do informacji. Np. na podstawie wspomnianej nazwy projektu agent może wczytać dodatkowe informacje na jego temat, lub pobrać dane z Internetu, aby wzbogacić opis. Z kolei w sytuacji, gdy nie będzie w stanie sobie poradzić z zadaniem ... może poprosić człowieka o pomoc.

<div style="padding:75% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/1005763540?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="0101_intro"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

No i właśnie budowaniem takich rozwiązań, będziemy zajmować się przez najbliższe tygodnie, zatem — witaj w AI_devs 3!

## Połączenie z modelem, od praktycznej strony

Na tym etapie zakładam, że materiały wdrożeniowe do AI_devs 3 masz już za sobą lub wracasz do nas z poprzednich edycji. W obu przypadkach posiadasz przynajmniej bazową wiedzę na temat modeli językowych. Możemy więc przejść do praktycznych przykładów interakcji z modelami.

Zacznijmy od tego, że domyślnie interakcja z modelem polega na budowaniu tablicy `messages` zawierającej treść konwersacji połączoną z instrukcją systemową, czyli format ChatML. Jednak nas interesuje kilka dodatkowych kwestii. 
 
Mianowicie fakt, że na wygenerowanie rezultatu w przypadku Agenta AI składa się wiele zapytań i wywołań funkcji. W przykładzie poniżej widzimy 4 etapy: 

- **Zrozumienie:** Wymaga wczytania pamięci i/lub dostępu do Internetu. W ten sposób wykraczamy poza bazową wiedzę modelu i zyskujemy informacje przydatne na dalszych etapach. Można to określić jako etap "zastanawiania się" lub "analizy".
- **Plan działań**: Wymaga połączenia wcześniejszych "przemyśleń" połączonych z listą dostępnych narzędzi, umiejętności lub innych agentów. Na tej podstawie tworzona jest lista akcji, która ma być zrealizowana w dalszych krokach. 
- **Podejmowanie działań**: Wymaga wiedzy, planu i dostępnych umiejętności, na podstawie których model decyduje o kolejnym kroku i gromadzi informacje zwrotne. 
- **Odpowiedź**: Wymaga wiedzy oraz raportu z działań w celu wygenerowania ostatecznej odpowiedzi.

![](https://cloud.overment.com/2024-09-02/aidevs3_plan-f0b12e52-d.png)

Już na tym etapie trzeba mieć na uwadze to, że powyższa interakcja, **nie musi uwzględniać zaangażowania ze strony człowieka** i może być realizowana "w tle" oraz trwać od kilku sekund do nawet kilku godzin. Może też być uruchamiana automatycznie według harmonogramu lub zewnętrznego zdarzenia.  

Widzimy też wyraźnie, że nie mówimy tutaj już o prostym budowaniu konwersacji przez tablicę `messages`, lecz nowej architekturze i wzorcach projektowania aplikacji. Co ciekawe, jest to programowanie które w ~80% przypomina klasyczne aplikacje, a LLM, Prompty czy narzędzia takie jak bazy wektorowe stanowią jedynie pewną część. Natomiast poza samym kodowaniem, zdecydowanie większą rolę odgrywa praca z danymi, różnymi formatami plików, organizacją baz danych czy strategiami wyszukiwania (tzw. retrieval). 

Wracając jednak do prowadzenia interakcji z modelem, to w przykładzie [`thread`](https://github.com/i-am-alice/3rd-devs/tree/main/thread) widzimy dość nietypowy, aczkolwiek bardzo przydatny sposób prowadzenia konwersacji. Zamiast każdorazowo przesyłać całą historię wiadomości do modelu, to stosujemy **podsumowanie** oraz jedynie **najnowszą wiadomość użytkownika**. Dzięki temu, nie potrzebujemy kompletnej konwersacji, aby model zapamiętał kluczowe informacje takie jak imię użytkownika. 

Aby uruchomić ten przykład, włącz serwer poleceniem `bun thread` i wykonaj zapytanie GET na adres `localhost:3000/api/demo`.

![](https://cloud.overment.com/2024-09-02/aidevs3_thread-676ee978-b.png)

Schemat tej interakcji wygląda następująco: po udzieleniu pierwszej odpowiedzi generowane jest podsumowanie dotychczasowej rozmowy, które jest dołączane do promptu systemowego kolejnej tury. W ten sposób przekazujemy "skompresowany" wątek.  

![](https://cloud.overment.com/2024-09-02/aidevs3_turns-faccf75e-d.png)

W wyniku takiej kompresji naturalnie tracimy część informacji. Nic jednak nie stoi na przeszkodzie, aby dodać mechanizm przeszukiwania wcześniejszych wątków na wypadek, gdyby podsumowanie było niewystarczające.

Przykład [`thread`](https://github.com/i-am-alice/3rd-devs/tree/main/thread) jest prosty, jednak doskonale obrazuje to, jak możemy manipulować przebiegiem konwersacji, a w rezultacie: 

- Fakt, że do podsumowania zastosowaliśmy tańszy model, jest przykładem **optymalizacji kosztów**
- Dzięki podsumowaniu model przetwarza mniejszą ilość treści, **przez co jego uwaga jest bardziej skupiona na aktualnym zadaniu** — **WAŻNE!** w modelach klasy GPT-4o jest to bardzo istotna kwestia, wpływająca na skuteczność działania modelu
- Podsumowanie pozwala także uniknąć limitu okna kontekstu, co ma znaczenie w przypadku modeli Open Source, które mogą odpowiadać za wybrany element interakcji (np. anonimizację)
- Podsumowanie może być również wykorzystane w innych częściach logiki agenta, a także jako element interfejsu użytkownika lub raportu pracy agent
- W tym przypadku zastosowaliśmy podsumowanie, jednak ten sam schemat będziemy stosować np. przy rozpoznawaniu obrazu, dźwięku czy wideo. Tam również dodatkowe zapytania do modelu będą wykorzystywane jako kontekst promptu systemowego
## Rodzaje interakcji

Złożona logika agentów składa się z modułów oraz pojedynczych akcji. Trudno mówić o dobrze działającym systemie, jeśli nie zadbamy o detale zarówno po stronie promptów, jak i po stronie kodu. Dlatego na tym etapie przejdziemy przez kilka przykładów elementarnych akcji, takich jak podejmowanie decyzji, klasyfikacja, parsowanie, transformacja i ocena. Wykorzystamy także narzędzie PromptFoo, którego uruchomienie omówiłem w lekcji S00E02 — Prompt Engineering i o którym będziemy jeszcze mówić w dalszych lekcjach, a aktualnie wystarczy nam jego uruchomienie.

Przykładem pojedynczej akcji, może być **podejmowanie decyzji** przez model na podstawie dostępnych danych. Można to porównać do instrukcji warunkowej `if` lub `switch`. Różnica polega na elastyczności, kosztem deterministycznego rezultatu. 

Poniższy scenariusz prezentuje logikę sprawdzającą czy do danego zapytania potrzebujemy skorzystać z wyszukiwarki internetowej. W pierwszej chwili taki scenariusz sugeruje zastosowanie Function Calling / Tool Use. Nie zawsze jednak będzie to oczywiste.

![](https://cloud.overment.com/2024-09-03/aidevs3_decision-a25871ac-c.png)

Mianowicie zakładamy tutaj, że natychmiast mamy komplet niezbędnych informacji potrzebnych do uruchomienia wyszukiwania, co zwykle nie jest prawdą. Połączenie np. z FireCrawl może wymagać pobrania listy dopuszczalnych domen, czy wygenerowania słów kluczowych na podstawie dodatkowego kontekstu wczytywanego z bazy danych.

W przykładzie [`use search`](https://github.com/i-am-alice/3rd-devs/tree/main/use_search) (wymaga zainstalowanego PromptFoo), mamy prompt odpowiadający za podejmowanie decyzji o zastosowaniu wyszukiwarki. Jego zadaniem jest wygenerowanie `0` lub `1` w celu klasyfikacji zapytania. Z tego powodu uwzględniłem w nim przykłady Few-Shot oraz zdefiniowałem zestaw zasad dopasowany do początkowych założeń. Następnie działanie takiego promptu jest automatycznie weryfikowane na kilkudziesięciu przykładach. 

![](https://cloud.overment.com/2024-09-03/aidevs3_promptfoo-09e8b046-b.png)

Podejmowanie decyzji przez LLM może uwzględniać potrzebę wybrania wielu opcji, a nie tylko jednej. Wówczas mówimy o klasyfikacji zapytania. Skoro jesteśmy już przy przeszukiwaniu Internetu, to pomocny będzie także prompt wybierający domeny, do których zawęzimy wyszukiwanie. Jest to przydatne, ponieważ autonomiczne przeglądanie stron www szybko prowadzi do niskiej jakości źródeł czy serwisów, które wymagają logowania lub blokują dostęp do treści.

Warto więc wypisać sobie listę adresów i opisać je tak, aby LLM mógł zdecydować kiedy je uwzględnić, a kiedy nie. Prompt realizujący to zadanie znajduje się w przykładzie [`pick_domains`](https://github.com/i-am-alice/3rd-devs/tree/main/pick_domains). 

![](https://cloud.overment.com/2024-09-03/aidevs3_domains-08f186d6-5.png)

W powyższym prompcie, w celu zwiększenia skuteczności, zastosowaliśmy także wariant Thought Generation, a konkretnie "zero-shot chain of thought". Mówimy tutaj o podniesieniu skuteczności, ponieważ w ten sposób dajemy LLM "czas na myślenie", które domyślnie widoczne jest w modelach `o1`. Dodatkowo fakt, że właściwość "\_thoughts" jest generowana na początku, jest powiązany z faktem, że modele językowe są obecnie autoregresyjne i treść tej pierwszej właściwości wpływa na treść kolejnych — zwiększając w ten sposób prawdopodobieństwo uzyskania oczekiwanych rezultatów. 

Pozostając w temacie przeszukiwania Internetu, jesteśmy gotowi na wykonanie zapytania do wyszukiwarki. Jednak na tym etapie możemy uzyskać jedynie wyniki w formacie znanym z Google czy DuckDuckGo. Oznacza to, że nie będą to wystarczające informacje do udzielenia finalnej odpowiedzi, ale możemy na ich podstawie wskazać strony, które będziemy chcieli wczytać.

W przykładzie `rate` znajduje się prompt oceniający to, czy zwrócony wynik może zawierać interesujące nas informacje. Na podstawie zwróconych ocen wybierzemy te strony, których zawartość będziemy chcieli wczytać z pomocą np. FireCrawl.

![Automatyczny test promptu oceniającego to, jak istotny jest context z punktu widzenia zapytania](https://cloud.overment.com/2024-09-04/aidevs_rate-7364bbb1-3.png)

Zbierając to w całość, mamy już: 

- Decyzję o tym czy wyszukiwarka internetu jest potrzebna
- Decyzję o tym, jakie zapytania chcemy do niej skierować
- Możliwość filtrowania zwróconych wyników

Pozostaje nam więc już tylko wygenerowanie odpowiedzi na oryginalne pytanie na podstawie pobranych danych. Zobaczmy, jak możemy to wszystko połączyć w całość w przykładzie [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch). Jego logika umożliwia zwykłą rozmowę z LLM, ale gdy wykryta zostanie konieczność skorzystania z wyszukiwarki, oryginalne zapytanie użytkownika zostaje wykorzystane do przeszukiwania sieci, co zresztą można zobaczyć na poniższym filmie. 

<div style="padding:56.25% 0 0 0;position:relative;"><iframe src="https://player.vimeo.com/video/1006292055?badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479" frameborder="0" allow="autoplay; fullscreen; picture-in-picture; clipboard-write" style="position:absolute;top:0;left:0;width:100%;height:100%;" title="01_01_websearch"></iframe></div><script src="https://player.vimeo.com/api/player.js"></script>

![Przykład kodu łączącego duży model z wyszukiwarką internetową](https://cloud.overment.com/2024-09-04/aidevs3_websearch-f14ad4e3-1.png)

## Architektura aplikacji

Patrząc nawet na przykład [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch), można zauważyć, że faktycznie ~80% kodu przypomina klasyczną aplikację. Jednak zgodnie z tym, co omawialiśmy w lekcji S00E04 — Programowanie, w kodzie zaczyna pojawiać się język naturalny oraz elementy, które do tej pory mogły odgrywać nieco mniejszą rolę w zależności od projektu.

Poza strukturą katalogów, podziałem odpowiedzialności, architekturą bazy danych czy samym stackiem technologicznym, pod uwagę musimy wziąć także rolę dużych modeli językowych oraz promptów. Nie chodzi tutaj wyłącznie o wybór modelu, hostingu czy napisaniu instrukcji, ale przede wszystkim o sposób przepływu danych.

Jeśli spojrzymy teraz na wizualizację przykładu [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch), to jasno widzimy, że działanie kolejnych promptów jest uzależnione od rezultatów poprzednich. Choć każdy z nich budujemy indywidualnie, to robiąc to, musimy brać pod uwagę dane na których będzie pracować, oraz to w jaki sposób generowane przez niego dane będą wykorzystane później. 

![](https://cloud.overment.com/2024-09-04/aidevs3_graph-f6782902-9.png)

Nieco bardziej rozbudowana wizualizacja pokazuje te zależności nieco wyraźniej. I tak nie jest to wszystko, bo mamy tutaj do czynienia z łańcuchem promptów i akcjami następującymi po sobie, a nie zawsze tak będzie.

![](https://cloud.overment.com/2024-09-04/aidevs3_advanced-734782e6-2.png)

Na blogu LangChain można przeczytać [o podstawach architektury kognitywnej](https://blog.langchain.dev/what-is-a-cognitive-architecture/), gdzie uwzględniony jest podział na Code, LLM Call, Chain, Router, a także State Machine i w pełni autonomiczne systemy o których będziemy jeszcze mówić. 

![](https://cloud.overment.com/2024-09-05/xnapper-2024-09-05-09.56.29-f389615d-4.png)

Tymczasem spróbujmy spojrzeć na to z szerokiej perspektywy, uwzględniając elementy, które w tej chwili pominęliśmy w celu uniknięcia dużej złożoności. 

- **Baza danych (np. PostgreSQL):** teraz nie tylko historia konwersacji rozpoczyna się za każdym razem od nowa. Treść wyników wyszukiwania oraz zawartość wczytanych stron również znikają po zakończeniu żądania. Zatem jeśli w kolejnej wiadomości użytkownik zada pytanie pogłębiające, będziemy musieli ponownie wczytywać te same dane. Widzimy więc, że **będziemy chcieli zapisać zarówno historię rozmowy, jak i kontekst wykorzystany do ich generowania**. Ogólny mechanizm widoczny jest we wcześniejszym przykładzie [`thread`](https://github.com/i-am-alice/3rd-devs/tree/main/thread), ale uwzględniał on wyłącznie treść rozmowy, bez dodatkowego kontekstu
- **Silnik wyszukiwania (np. Qdrant):** zapisując wspomniane dane, szybko dojdziemy do momentu gdy wczytanie ich wszystkich do kontekstu stanie się nieopłacalne lub wprost niemożliwe. Wówczas kluczowe będzie ich skuteczne odszukiwanie. Musimy zatem pomyśleć o tym, jak je skutecznie zorganizować i opisać, a potem przeszukiwać oraz przekazywać do modelu.
- **Zarządzanie stanem**: podobnie jak w przypadku klasycznych aplikacji, tutaj także do gry wchodzi zarządzanie stanem. Jednak tutaj przechowywane dane będą obejmować historię promptów czy historię uruchomionych narzędzi wraz z informacją zwrotną.
- **API:** w przypadku [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch) mamy do czynienia tylko z dwoma narzędziami (web search i web scrapping), jednak zwykle będzie ich znacznie więcej. Każde z nich musi zostać zbudowane tak, aby LLM mógł się nim posługiwać, rozumieć odpowiedzi oraz obsługiwać błędy
- **Ewaluacja promptów**: Patrząc na powyższy schemat, staje się jasne, dlaczego wcześniej przechodziliśmy przez PromptFoo oraz dlaczego będziemy modyfikować prompty, testując je automatycznie na wybranych zestawach testowych.
- **Wersjonowanie i kopie zapasowe:** wersjonowanie odnosi się już nie tylko do historii kodu oraz promptów, lecz także do zmian wprowadzanych przez model. Przykładowo, agent zarządzający listą zadań może przypadkowo zmodyfikować wpisy, których nie chcemy edytować, i musimy mieć łatwy sposób ich przywrócenia.
- **Kontrola uprawnień**: w przykładzie [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch) programistycznie ograniczyłem listę domen z którymi LLM może się skontaktować. W podobny sposób będziemy określać uprawnienia modelu w celu zwiększenia stabilności aplikacji. 
- **Monitorowanie aplikacji:** w przykładzie [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch) historię wykonanych zapytań zapisałem w pliku markdown. Naturalnie, nie będzie to wystarczające w produkcyjnych aplikacjach, gdzie będziemy korzystać z LangFuse czy podobnych rozwiązań do zaawansowanego monitorowania.
- **Asynchroniczność:** narzędzie [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch) pokazuje, że LLM może działać w tle, co wydłuża czas reakcji. W takim przypadku sensowne jest uruchamianie skryptu "w tle" lub utworzenie kolejki, po której wykonaniu użytkownik otrzyma powiadomienie lub e-mail z informacją o zakończeniu zadania.
- **Interfejs:** narzędzie [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch) może być wykorzystane w interfejsie czatu, co pokazałem na filmie. Jednak równie dobrze mógłby to być formularz umożliwiający dodanie listy adresów oraz związane z nimi zadania (np. "pobierz najnowszy artykuł") wraz z harmonogramem uruchomienia. 

Wszystkimi z wyżej wymienionych punktów będziemy zajmować się w dalszych lekcjach, ale nie wszystkie będą wymagane za każdym razem. Będziemy tworzyć zarówno proste narzędzia odpowiedzialne za nieskomplikowane akcje, jak i rozbudowane rozwiązania wspierające złożone procesy.

## Optymalizacja skuteczności

Instrukcje z przykładów [`pick_domains`](https://github.com/i-am-alice/3rd-devs/tree/main/pick_domains), [`use_search`](https://github.com/i-am-alice/3rd-devs/tree/main/use_search) czy [`rate`](https://github.com/i-am-alice/3rd-devs/tree/main/rate) zawierają od kilku do kilkunastu przykładów Few-Shot. W niektórych przypadkach może być ich nawet kilkadziesiąt czy kilkaset i wówczas mówimy o "in-context learningu w oparciu o przykłady 'many-shot'" o których możemy przeczytać w [Many-Shot In Context Learning](https://arxiv.org/abs/2404.11018).

![](https://cloud.overment.com/2024-09-05/aidevs3_manyshot-4edd19f3-b.png)

Uwzględnienie przykładów jest pierwszą techniką, którą powinniśmy brać pod uwagę przy optymalizacji skuteczności promptu. Poprzez prezentowanie oczekiwanego zachowania w ten sposób, możemy wzmocnić treść głównej instrukcji. 

Samym projektowaniem przykładów będziemy zajmować się w dalszych lekcjach, natomiast na teraz musisz wiedzieć, że:

- Przykłady zwykle mają formę par prezentujących dane wejściowe (wiadomość użytkownika) oraz dane wyjściowe (odpowiedź modelu)
- Liczba przykładów zwykle nie przekracza ~3 - 40 par
- Przykłady powinny prezentować oczekiwane zachowanie i być zróżnicowane oraz uwzględniać sytuacje brzegowe (np. takie w których zachowanie modelu ma być inne niż oczekiwane)
- Przykłady muszą być dobrane starannie, lecz do ich generowania możemy wykorzystać pomoc ze strony modelu
- Przykłady docelowo mogą być wykorzystane na potrzeby Fine-Tuning, a ich warianty na potrzeby automatycznych testów
- Duża liczba przykładów może być połączona [z mechanizmem cache'owania](https://www.anthropic.com/news/prompt-caching) w celu optymalizacji kosztów oraz wydajności

Technikami dobierania przykładów i pracy z nimi, będziemy zajmować się w dalszej części AI_devs 3. Tymczasem Few-Shot możesz zapamiętać jako nieodłączny element praktycznie każdego promptu. 
## Podstawy pamięci długoterminowej

Wczytywanie treści z wyszukiwarki oraz stron www do promptu w celu odpowiadania na pytania na ich podstawie to przykład Retrieval-Augmented Generation. Tutaj z pomocą FireCrawl rozszerzyliśmy bazową wiedzę modelu dokładnie w taki sposób, jak będziemy robić to w przypadku baz wiedzy czy pamięci tymczasowej oraz długoterminowej agenta. Jest to prawdopodobnie znany Ci już schemat, widoczny poniżej, w którym wskazujemy modelowi treść, którą ma wykorzystać przy generowaniu odpowiedzi. 

![](https://cloud.overment.com/2024-09-05/aidevs3_rag-1d9ef809-b.png)

Analogicznie będziemy wczytywać dane z plików, baz danych czy zewnętrznych usług. Przykład [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch) pokazał nam jednak, że na odszukanie informacji będzie składać się szereg dodatkowych kroków, związanych z parafrazą zapytania, generowaniem dodatkowych zapytań (tzw. Self-Querying), ocenianiem wyników (tzw. Re-rank) i ich filtrowaniem. 

Należy mieć tutaj na uwadze fakt, że podłączanie zewnętrznych źródeł wiedzy do naszego systemu może mieć bardzo negatywny wpływ na jego działanie. To właśnie z tego powodu ograniczyłem listę domen dla FireCrawl, ale takich sytuacji jest więcej. Chociażby wczytywanie dokumentu PDF może wiązać się z utratą formatowania, co zaburzy zrozumienie jego zawartości. 

Problemy z formatowaniem to także nie wszystko, ponieważ stale musimy mieć na uwadze ograniczoną wiedzę LLM na temat naszego kontekstu. Przykładowo jeśli powiemy "Zapamiętaj, że overment to mój nickname", to system powinien zapamiętać "Nickname Adama to overment". W przeciwnym razie w przyszłości może uznać, że 'overment' to jego nickname, czego przykład mamy poniżej. 

![](https://cloud.overment.com/2024-09-05/aidevs3_nickname-b04b7bd3-c.png)

O pamięci długoterminowej dla modelu będziemy jeszcze mówić w module trzecim AI_devs 3. Na ten moment zapamiętaj, że:

- Jakość wypowiedzi modelu zależy od promptu, ale także od dostarczonych danych
- Instrukcja powinna zawierać informacje na temat tego, jak model powinien wykorzystywać kontekst w swoich wypowiedziach
- Jeden prompt może zawierać wiele zewnętrznych kontekstów, jednak powinny być one wyraźnie od siebie oddzielone
- Model powinien posiadać instrukcję u zachowaniu w sytuacji, gdy dostarczony kontekst jest niewystarczający do udzielenia odpowiedzi
- Musimy zadbać nie tylko o jakość źródeł dostarczanych informacji, ale także o sposób ich przechowania i dostarczenia do modelu. Wspomniana wyżej parafraza wspomnienia pokazuje, że zawsze musimy zadawać sobie pytanie: **Jak model będzie wykorzystywać dostarczoną wiedzę?**

## Podsumowanie

Niniejsza lekcja to przedsmak tego, czym będziemy zajmować się w nadchodzących tygodniach. Jej celem było pokazanie szerokiej perspektywy na temat aplikacji wykorzystujących LLM, a przede wszystkim tego, że w dużym stopniu są one budowane tak samo, jak oprogramowanie, które tworzymy na co dzień.

To właśnie z tego powodu, jednym z wymagań AI_devs 3 była znajomość przynajmniej jednego języka programowania. Co prawda nie wszystkie z omawianych elementów będziemy wdrażać samodzielnie i nie musimy posiadać doświadczenia w budowie baz danych czy optymalizacji silników wyszukiwania. Pomimo tego w nadchodzących tygodniach będziemy mieć kontakt z najróżniejszymi zagadnieniami, które mogą być dla Ciebie zupełnie nowe. Potraktuj to więc jako możliwość doświadczenia szerokiej perspektywy rozwoju aplikacji, a najwięcej uwagi skieruj na obszary, które Ciebie dotyczą (np. front-end, back-end czy bazy danych). 

Po dzisiejszej lekcji spróbuj przynajmniej uruchomić przykład [`websearch`](https://github.com/i-am-alice/3rd-devs/tree/main/websearch) i zadać mu kilka pytań w celu sprawdzenia jak się w nich odnajduje. Istnieje dość duże prawdopodobieństwo, że nie odpowie skutecznie na Twoje pytania — zastanów się wtedy dlaczego tak się dzieje. Przejdź przez prompty z pliku `prompts.ts` oraz sprawdź jak skutecznie FireCrawl radzi sobie z wczytywaniem treści stron, z którymi chcesz pracować.

Możesz także poświęcić chwilę na pracę z PromptFoo, którego podstawową konfigurację omawiałem w materiale wdrożeniowym i lekcji S00E02 — Prompt Engineering. Do pracy z tym narzędziem wykorzystaj Cursor IDE z wczytaną dokumentacją, co ułatwi generowanie plików konfiguracyjnych oraz szybsze zrozumienie tego rozwiązania.

Zamykając klamrą dzisiejszą lekcję, to już na tym etapie powinno być dla Ciebie zrozumiałe to, że LLM w kodzie aplikacji pozwala na sprawne przetwarzanie języka naturalnego, a także różnych formatów danych (np. audio czy obrazu). Daje to nam nowe możliwości, ale nadal fundamentem rozwoju aplikacji pozostaje Twoja wiedza oraz doświadczenie.