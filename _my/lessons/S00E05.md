![](https://cloud.overment.com/S00E05-2-1730634581.png)

# S00E05 — Rozwój

Programowanie to umiejętność, która zwykle kojarzy się z aktywnością zawodową i nierzadko projektami realizowanymi po godzinach. Z jakiegoś powodu stosowanie jej w celu zbudowania narzędzi przydatnych na co dzień, jest dość rzadkie. Jednocześnie to właśnie w takim przypadku możemy stworzyć środowisko na wzór piaskownicy, w której możemy uczyć się nowych rzeczy, eksplorować narzędzia czy popełniać błędy. 

Tworzenie takich projektów po godzinach nie jest łatwe. Nie każdy chce poświęcać czas na aktywności podobne do tych realizowanych na etacie czy we własnej firmie. Jednak od czasu popularyzacji LLM przez ChatGPT, mamy do dyspozycji narzędzie, dzięki któremu znacznie szybciej zbudujemy prototyp, zrozumiemy dokumentację, skonfigurujemy serwer czy znajdziemy błąd w kodzie.

Nietrudno zauważyć, że generatywne AI rozwija się bardzo szybko i ciągle pojawiają się nowe techniki oraz narzędzia. Podobnie jest w obszarach programistycznych, gdzie obserwujemy nowe wersje frameworków i bibliotek. W rezultacie nadążanie za zmianami w branży stanowi duże wyzwanie, dlatego warto wykorzystać umiejętność programowania, aby to sobie ułatwić.
## Budowanie własnych narzędzi i API

Frameworki takie jak [Next.js](https://nextjs.org/) czy [Nest.js](https://nestjs.com/) bardzo ułatwiają budowanie własnego API nawet jeśli nie posiadamy dużego doświadczenia na back-endzie. Przez 'prywatne API' mam na myśli zestaw funkcji realizujących działania z naszej codzienności. Przykłady to: **zarządzanie zadaniami, kalendarzem, wiadomościami, przetwarzanie dokumentów czy udostępnianie plików.**

Poniższa lista uwzględnia podział API na kilka kategorii: 

- **Przetwarzanie plików:** typowe akcje wykonywane na plikach, co wymaga ich podziału na mniejsze fragmenty (tzw. Chunking) oraz precyzyjnego przetwarzania fragmentami
- **Pamięć długoterminowa:** mechanizm pamięci dla agenta AI, obejmujący możliwość zapamiętywania informacji i posługiwania się nimi podczas rozmowy, a nawet wykonywania zadań
- **Aplikacje i Urządzenia:** integracja z aplikacjami i urządzeniami poprzez API, co pozwala na automatyzację czynności związanych z ich obsługą
- **Dostęp do sieci:** dostęp do wyszukiwarki, stron Internetowych czy zarządzania systemem CMS
- **Code Interpreter:** samodzielne uruchamianie wygenerowanego kodu
- **Generowanie obrazów:** możliwość generowania i transformacji obrazów

![Schemat 'osobistego AGI', składającego się z modułów pozwalających na wykonywanie codziennych zadań](https://cloud.overment.com/2024-08-23/aidevs3_agi-b9edf2f0-4.png)

Całość można określić (z przymróżeniem oka) jako 'osobiste AGI', ponieważ powyższym API może posługiwać się Agent AI z którym możemy współpracować, przesyłając mu zwykłe wiadomości na Slacku czy polecenia głosowe przez Siri.

Zestaw wymienionych powyżej modułów, może być też ograniczony do konkretnego obszaru, np. pracy z kodem czy bazą wiedzy. Jednak w każdym przypadku mówimy tutaj o sytuacji w której posiadamy API z którego korzystamy za pośrednictwem asystenta AI. Co ciekawe, interakcja z asystentem może odbywać się przez różne interfejsy. 
## Wybór zestawu technologicznego

Do zbudowania API, poza technologią backendową i frameworkiem, będziemy potrzebować także kilku dodatkowych narzędzi. W przypadku większości z nich wystarczą nam bezpłatne plany oraz też nie wszystkie z nich będą nam niezbędne. 

- Model: Claude 3.5 Sonnet (Anthropic), GPT-4o (OpenAI), Gemma 27B (DeepMind), Whisper (speech to text), TTS (OpenAI, text to speech)
- Hosting (VPS): DigitalOcean lub [Mikr.us](https://mikr.us/)
- Baza danych: SQLite, PostgreSQL (np. przez [xata.io](https://xata.io/)) lub inna, dopasowana do własnych preferencji oraz ORM, np. Prisma lub [DrizzleORM](https://orm.drizzle.team/)
- Silnik wyszukiwania: Qdrant, [Algolia](https://www.algolia.com/), [Chroma](https://www.trychroma.com/), [Supabase](https://supabase.com/pricing)
- Przeszukiwanie sieci: FireCrawl, [Crawlee](https://crawlee.dev/) [Tavily](https://tavily.com/#api), [BraveSearch](https://brave.com/search/api/), [exa.ai](https://exa.ai/)
- Code Interpreter: e2b, [Open Interpreter](https://github.com/OpenInterpreter/open-interpreter)
- Generowanie obrazów: [Ideogram](https://ideogram.ai/manage-api), [Leonardo](https://leonardo.ai/), [Stable Diffusion 3](https://platform.stability.ai/docs/api-reference#tag/Generate/paths/~1v2beta~1stable-image~1generate~1sd3/post), [HTMLCSSToImage](https://htmlcsstoimage.com/)
- Transkrypcje: [Insanely Fast Whisper](https://github.com/Vaibhavs10/insanely-fast-whisper)
- Interfejsy: Slack / Telegram / Siri Shortcuts
- Aplikacja do zadań: [Linear](https://linear.app/), [Todoist](https://todoist.com/), [ClickUp](https://clickup.com/)
- Aplikacja do notatek: [Notion](https://www.notion.so/)
- Aplikacja do aktualności: [Feedly](https://feedly.com/), [Readwise](https://read.readwise.io/) 
- Automatyzacje no-code: [make.com](https://www.make.com/), [n8n](https://n8n.io/), [buildship](https://buildship.app/)

W przypadku prywatnego API, warto wybrać takie technologie i narzędzia, które pozwolą nam możliwe szybko się poruszać i skupić na generowaniu wartości. Wyjątek stanowią sytuacje w których celowo wybieramy nową, trudną dla nas ścieżkę, aby np. nauczyć się obsługi nowego narzędzia.

Dodatkowo kluczową zmienną, którą musimy brać pod uwagę jest fakt, aby usługi, narzędzia, aplikacje i urządzenia, które wybieramy, miały dostępne dobrze prowadzone API. Można powiedzieć, że w tej sytuacji będzie nam zależało na odejściu od graficznego interfejsu, na rzecz programistycznych integracji. 

## Przydatne narzędzia

Choć wspominany już LangChain nie ma obecnie dobrej reputacji w kontekście produkcyjnym, tak skorzystanie z jego elementów na własne potrzeby może okazać się dobrą decyzją. Podobnie sytuacja wygląda z narzędziami takimi jak CrewAI, [LangGraph](https://langchain-ai.github.io/langgraph/) oraz [LangFlow](https://www.langflow.org/). Każde z tych narzędzi dynamicznie się rozwija, więc warto obserwować zmiany wprowadzane w nowych wersjach, a także konkurencyjne rozwiązania pojawiające się na rynku.

W treści lekcji AI_devs 3 omawiałem i będę omawiał mnóstwo różnych narzędzi i platform. Części z nich poświęcimy więcej czasu, a inne zostaną tylko wspomniane. Natomiast poniższa lista to zestaw ogólnych rozwiązań, o których istnieniu warto wiedzieć. 

- ollama: Aplikacja dzięki której z łatwością uruchomimy modele Open Source i połączymy się z nimi przez API (w formacie OpenAI)
- [exo](https://github.com/exo-explore/exo): Narzędzie umożliwiające połączenie ze sobą urządzeń Apple na potrzeby inferencji modeli Open Source
- ElevenLabs (lub [Deepgram](https://deepgram.com/) lub [Hume.ai](https://www.hume.ai/)): Platformy udostępniające modele Text To Speech / Text To Audio (tylko Elevenlabs)  
- [Superwhisper](https://superwhisper.com/) (lub [Flow](https://www.flowvoice.ai/)): Aplikacja speech-to-text, ułatwiająca głosowe wprowadzanie tekstu
- [v0](https://v0.dev/): Narzędzie do generowania interfejsów użytkownika na podstawie promptu
- Unstructured: Narzędzie do strukturyzowania danych na potrzeby RAG
- Unsloth: Platforma ułatwiająca fine-tuning modeli Open Source
- Replicate: Platforma oferująca dostęp do różnych modeli przez API
- OpenRouter: Platforma oferująca dostęp do różnych modeli językowych przez API
- [RunPod](https://www.runpod.io/): Platforma umożliwiająca wynajęcie GPU
- [comfyUI](https://github.com/rugovit/ComfyUI-Mac-Installer): Zaawansowany, wizualny interfejs do generowania grafik z pomocą np. [Flux](https://blackforestlabs.ai/)
- [PrivateGPT](https://github.com/zylon-ai/private-gpt): Narzędzie open source, umożliwiające rozmowę z dokumentami z zachowaniem prywatności
- [AgentOps](https://github.com/AgentOps-AI/agentops): Podobnie jak LangFuse czy LangSmith, ułatwia monitorowanie Agentów AI
- [RunwayML](https://runwayml.com/): Narzędzie do generowania wideo na podstawie tekstu i/lub obrazu

Za każdym z wymienionych narzędzi stoją ludzie, którzy często dzielą się swoją wiedzą na profilach X, Medium czy Substack. Dodatkowo, powstają wokół nich społeczności, do których warto dołączyć, aby odkrywać nowe techniki pracy oraz inne rozwiązania.

## Wartościowe źródła wiedzy

Choć praktyczne doświadczenie jest niezastąpionym sposobem nauki, tak warto sięgać także po sprawdzone źródła wiedzy oraz rzetelnie raportowane aktualności. 

- [Stanford Online](https://www.youtube.com/@stanfordonline): Kanał YouTube z nagraniami wykładów wśród których można znaleźć wątki związane z generatywnym AI i dużymi modelami językowymi
- [ArXiv Papers](https://github.com/dair-ai/ML-Papers-of-the-Week): Lista najciekawszych publikacji pojawiających się na ArXiv w tematach związanych z branżą AI
- [StatQuest](https://www.youtube.com/@statquest): Kanał YouTube, który (z dość charakterystycznym humorem) wyjaśnia zagadnienia związane między innymi z LLM
- [3blue1brown](https://www.youtube.com/c/3blue1brown): Podobnie jak StatQuest, publikuje bardzo jakościowe filmy, nierzadko poruszające wątki generatywnego AI
- [AI Explained](https://www.youtube.com/@aiexplained-official): Kanał YouTube skupiający się głównie na komentowaniu i analizie publikacji naukowych oraz wydarzeń z branży
- [AI Engineer](https://www.youtube.com/@aiDotEngineer/videos): Kanał YouTube z nagraniami z różnych wystąpień i warsztatów
- [Andrej Karpathy](https://www.youtube.com/@AndrejKarpathy): Kanał YouTube jednej z najbardziej rozpoznawalnych postaci w branży. Karpathy jest byłym szefem autopilota Tesli i przez kilka lat był zaangażowany w rozwój OpenAI
- [Anthropic Research](https://www.anthropic.com/research): Choć niemal wszystkie firmy stojące za najlepszymi modelami językowymi dzielą się swoimi doświadczeniami na blogach, to w przypadku Anthropic można znaleźć bardzo praktyczną wiedzę i techniki pracy z modelami
- [Prompt Engineering Guide (Anthropic)](https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/overview): Zestaw porad na temat projektowania promptów od Anthropic
- [Prompt Engineering Guide (OpenAI)](https://platform.openai.com/docs/guides/prompt-engineering): Zestaw porad na temat projektowania promptów od OpenAI
- [Prompt Engineering Guide](https://www.promptingguide.ai/): Zestaw porad na temat projektowania promptów, rozwijany przez DAIR.AI
- [LMSYS](https://lmarena.ai/): To organizacja stojąca między innymi za Chatbot Areną i rankingiem [LMSYS Chatbot Arena Leaderboard](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard)
- [Deeplearning.ai](https://www.deeplearning.ai): To platforma z kursami online rozwijanymi przez [Andrew Ng](https://x.com/AndrewYNg)
- [Code Your Own AI](https://www.youtube.com/@code4AI): To niszowy, choć interesujący kanał na YouTube, łączący praktykę z teorią
- [LifeArchitect](https://lifearchitect.ai/): To strona gromadząca najważniejsze publikacje, aktualności oraz (potencjalne) informacje na temat nadchodzących modeli
- [Matthew Berman](https://www.youtube.com/@matthew_berman): To kanał YouTube skupiający się na aktualnościach, testach nowych modeli i popularnych narzędzi GenAI

Poza wymienionymi wyżej źródłami, warto obserwować także profile takie jak: 

- [Yann LeCun](https://x.com/ylecun): Szef Meta AI, stojący między innymi za modelami Llama. Aktywny na X, ale w sieci można spotkać wiele wartościowych rozmów z nim
- [Geoffrey Hinton](https://x.com/geoffreyhinton): Określany mianem "ojca chrzestnego obecnego AI", który mocno przyczynił się do rozwoju generatywnego AI
- [Ilya Sutskever](https://x.com/ilyasut): Od czasu odejścia z OpenAI nie jest aktywny w sieci, lecz na YouTube można znaleźć jego wykłady i wystąpienia. Ilya uznawany jest za "osobę stojącą za ChatGPT"
- [Pliny the Liberator](https://x.com/elder_plinius): Publikuje wpisy głównie na temat Jailbreakingu modeli i związanych z tym zagrożeń oraz możliwości
- [Georgi Gerganov](https://x.com/ggerganov): Twórca llama.cpp, zajmuje się głównie modelami Open Source
- [Awni Hannun](https://x.com/awnihannun): Główna osoba stojąca za Apple MLX i podobnie jak Gerganov zajmuje się modelami Open Source
- [Elvis](https://x.com/omarsar0): Researcher mówiący głównie o najnowszych publikacjach i odkryciach. Rozwija organizację [DAIR.AI](https://github.com/dair-ai
- [Stephen Wolfram](https://x.com/stephen_wolfram): Twórca modelu Wolfram Alpha, obecnie publikuje także materiały obejmujące Generatywne AI
- [Robert Scoble](https://x.com/Scobleizer): Codziennie udostępnia wartościowe treści i gromadzi społeczność osób skupionych wokół generatywnego AI i najnowszych technologii

Choć źródeł wiedzy wartych obserwowania jest znacznie więcej, warto zacząć od tych wymienionych powyżej. Wśród publikowanych przez nie treści można znaleźć inne godne uwagi źródła wiedzy i narzędzia. Dobrze jest więc wyrobić sobie nawyk przeglądania mediów społecznościowych (głównie X i YouTube) pod kątem profili obserwowanych przez osoby, które wnoszą nam wartość.
## Pogłębianie wiedzy w obszarze AI

AI jest bardzo obszerną dziedziną, a w AI_devs 3 skupiamy się przede wszystkim na generatywnym AI, a w szczególności na dużych modelach językowych. Nie schodzimy jednak w niskopoziomowe tematy związane z ich budowaniem od podstaw, lecz korzystaniem z ich możliwości poprzez API. 

Już po pierwszych lekcjach można zauważyć, że miejscami wchodzimy w nieco bardziej zaawansowane obszary (np. mówiąc o tokenach, Fine-Tuningu czy pracy z modelami Open Source) i nie dzieje się tak bez powodu. Wiedza na temat działania modeli, ich budowy, procesu trenowania, alignment'u czy ogólnego kierunku rozwoju jest potrzebna po to, aby móc skuteczniej z nimi pracować. 

Możliwy jest także rozwój własnej kariery w obszarze AI, co także będzie wymagać zdobycia wiedzy i umiejętności wykraczających poza materiał AI_devs (choć ten może stanowić dobry punkt startowy). W takiej sytuacji przydatne mogą okazać się poniższe źródła:

- [What is ChatGPT Doing?](https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/)
- [Build a Large Language Model](https://www.amazon.com/Build-Large-Language-Model-Scratch/dp/1633437167)
- [Let's reproduce GPT-2](https://www.youtube.com/watch?v=l8pRSuU81PU)
- [Let's build the GPT Tokenizer](https://www.youtube.com/watch?v=zduSFxRajkE&t=1241s)
- [Stanford CS25](https://www.youtube.com/playlist?list=PLoROMvodv4rNiJRchCzutFw5ItR_Z27CM)

(nieco luźniejsze, choć inspirujące):
- [The Singularity is Nearer](https://www.goodreads.com/book/show/45024007-the-singularity-is-nearer)
- [Why Machines Learn](https://www.goodreads.com/book/show/195888801-why-machines-learn)
- [Genius Makers](https://www.goodreads.com/book/show/55051662-genius-makers?from_search=true&from_srp=true&qid=11ZoY1Wx39&rank=1)

Zagadnienia związane z architekturą "Transformers" czy "Attention Mechanism" mogą być początkowo trudne do zrozumienia. Mogą też wydawać się odległe od tego, czym zajmujemy się podczas pracy z LLM przez API. Bez wątpienia jednak zrozumienie nawet wybranych koncepcji pozwala na bardziej świadomą pracę z modelami i korzystanie z ich możliwości. 
## Pozostawanie na bieżąco

Ogromny zakres wiedzy, umiejętności i narzędzi, który omówiliśmy, może być trudny do przyswojenia. Sprawy nie ułatwia fakt, że niemal każdego tygodnia pojawiają się nowe rozwiązania i modele, co utrudnia nadążanie za tym wszystkim. Mówiąc wprost — jest to niemożliwe.

Dlatego zamiast skupiać się na tym, co nam umyka lub samodzielnie testować wszystkie pojawiające się nowości, wystarczy tylko skupić się na najbardziej wartościowych źródłach wiedzy i otoczyć się nimi. Mam tutaj na myśli zasubskrybowanie kanałów na YouTube, obserwowanie profili na X czy zapisanie się do newsletterów. W ten sposób najważniejsze tematy będą docierać do nas z każdej strony i w końcu uda nam się wychwycić sygnał spośród szumu. 

Niestety w sieci pojawia się mnóstwo informacji, które nie mają zbyt wiele wspólnego z rzeczywistością. Różnego rodzaju benchmarki, prototypy czy zapowiedzi przełomowych rozwiązań, rzadko przekładają się na praktykę i mają w sobie więcej marketingowej narracji niż realnej wartości.

Właśnie z tego powodu wspomniany projekt "prywatnego API" czy też "osobistego AGI" odgrywa istotną rolę w eksplorowaniu generatywnego AI. Po prostu w ten sposób mamy okazję do samodzielnego przetestowania nowych rozwiązań i bliższego poznania popularnych technik pracy, a także kształtowania własnych.

## Współpraca z LLM w nauce i programowaniu

Generowanie treści bezpośrednio przez LLM zwykle charakteryzuje się wysokim poziomem konfabulacji, niewystarczającą jakością wypowiedzi lub po prostu niedopasowaniem jej do naszego kontekstu. Wiemy jednak, że model może pracować na informacjach dostarczonych przez nas do promptu. Co prawda nadal istnieje ryzyko wygenerowania błędnych treści, jednak dzieje się to zdecydowanie rzadziej. 

Wartość, jaką daje nam współpraca z LLM jest proporcjonalna do możliwości samego modelu oraz naszych umiejętności pracy z nim. Obie te rzeczy możemy ze sobą połączyć, wspierając się przy tym kilkoma narzędziami. 

Przede wszystkim, dopasowanie LLM do naszych potrzeb wymaga napisania głównego promptu systemowego, zawierającego najważniejsze zasady generowania wypowiedzi. Przykład takiego promptu znajduje się poniżej i skupia się na stylu wypowiedzi, sposobie rozumowania, czy wykorzystywanych technologiach. 

```
When answering, strcitly follow these rules:

<rules>
- Think aloud before you answer and NEVER rush with answers. Be patient and calm.
- Ask questions to remove ambiguity and make sure you're speaking about the right thing
- Ask questions if you need more information to provide an accurate answer.
- If you don't know something, simply say, "I don't know," and ask for help.
- By default speak ultra-concisely, using as few words as you can, unless asked otherwise
- When explaining something, you MUST become ultra comprehensive and speak freely
- Split the problem into smaller steps to give yourself time to think.
- Start your reasoning by explicitly mentioning keywords related to the concepts, ideas, functionalities, tools, mental models .etc you're planning to use
- Reason about each step separately, then provide an answer.
- Remember, you're speaking with an experienced full-stack web developer who knows JavaScript, Node.js, Rust, and common web technologies.
- Always enclose code within markdown blocks.
- When answering based on context, support your claims by quoting exact fragments of available documents, but only when those documents are available. Never quote documents that are not available in the context.
- Format your answer using markdown syntax and avoid writing bullet lists unless the user explicitly asks for them.
- Continuously improve based on user feedback.
</rules>
```

Więcej inspiracji dla takich promptów można znaleźć na stronie [cursor.directory](https://cursor.directory) i choć skupiają się na instrukcjach dla Cursor IDE, to widoczne w nich schematy można stosować także w innych kontekstach pracy z modelami.

Dobrze jest także zdecydować o sposobie interakcji z LLM i wybrać pomiędzy ChatGPT, Perplexity, Claude.ai lub ewentualnie klientem desktopowym. Główna idea polega tutaj na tym, aby zawsze mieć łatwy dostęp do LLM, który uwzględnia instrukcję systemową dopasowaną do nas. 

Kolejnym etapem w pracy z LLM jest dołączenie szerszego kontekstu, który może obejmować dynamiczne informacje na nasz temat lub aktualnie omawianego problemu. Przykładowo podczas pracy z nową biblioteką, możemy pobrać ją na swój komputer i uruchomić Cursor, a zadać pytanie na temat konfiguracji projektu lub konkretnych pytań z którymi mamy problem, a które nie zostały uwzględnione w dokumentacji.

![Cursor IDE pozwala na rozmowę z kodem całego projektu, co ułatwia poznawanie bibliotek lub eksplorację nowych projektów](https://cloud.overment.com/2024-08-24/aidevs3_codebase-21b9e048-1.png)

Podobnie można pracować z dokumentacją, której treść także może trafić do kontekstu. Cursor domyślnie oferuje dostęp do dokumentacji popularnych narzędzi i frameworków, ale także daje możliwość wczytania dokumentacji na podstawie adresu URL. Co prawda w tym przypadku często i tak będziemy chcieli zajrzeć do konkretnych podstron, jednak praca na takim kontekście zwiększa skuteczność generowanego kodu i często uwzględnia metody, o których sami nie wiedzieliśmy, a które faktycznie są dostępne. 

![Cursor IDE umożliwia przeszukiwanie dokumentacji i generowania odpowiedzi na podstawie znalezionych w niej informacji](https://cloud.overment.com/2024-08-24/aidevs3_docs-f64ea484-8.png)

Zatem podczas pracy i nauki przydatny jest nawyk korzystania z LLM, jednak zamiast opierać się wyłącznie o bazową wiedzę modelu, znacznie lepiej jest skorzystać z narzędzi umożliwiających łatwe dołączenie dodatkowego kontekstu.

Nie zawsze jednak nasze zadania będą powiązane z kodem czy dokumentacjami narzędzi. Wówczas wartość znajdziemy w aplikacjach oferujących możliwość "rozmawiania z plikami", przeszukiwania Internetu czy przetwarzania różnych formatów plików (np. audio czy wideo).
## Podsumowanie

Rozwój w obszarze Generatywnej Sztucznej Inteligencji można sprowadzić do **połączenia praktyki z najlepszymi źródłami wiedzy**. Pomimo dynamicznego tempa rozwoju, otoczenie się wartościowymi materiałami oraz realizowanie projektu w ramach swoich zainteresowań wystarcza do skutecznego zdobywania nowych umiejętności. Co więcej, w każdej z tych aktywności może towarzyszyć nam AI.